#include	<wb.h>

#define CUDA_STREAM_COUNT 4
#define BLOCK_SIZE 256
#define SEGMENT_SIZE 1024

__global__ void vecAdd(float * in1, float * in2, float * out, int len) {
    //@@ Insert code to implement vector addition here
	int i = blockIdx.x * blockDim.x + threadIdx.x;
	if(i < len) out[i] = in1[i] + in2[i];
}

int main(int argc, char ** argv) {
    wbArg_t args;
    int inputLength;
    float * hostInput1;
    float * hostInput2;
    float * hostOutput;
    float * deviceInput1[4];
    float * deviceInput2[4];
    float * deviceOutput[4];

    args = wbArg_read(argc, argv);

    wbTime_start(Generic, "Importing data and creating memory on host");
    hostInput1 = (float *) wbImport(wbArg_getInputFile(args, 0), &inputLength);
    hostInput2 = (float *) wbImport(wbArg_getInputFile(args, 1), &inputLength);
    hostOutput = (float *) malloc(inputLength * sizeof(float));
    wbTime_stop(Generic, "Importing data and creating memory on host");
	
	wbLog(TRACE, "The input length is ", inputLength);
	
	int segmentSize = SEGMENT_SIZE * sizeof(float);
	int segments = ((inputLength - 1)/(SEGMENT_SIZE*CUDA_STREAM_COUNT)) + 1;
	int n = segments * (SEGMENT_SIZE*CUDA_STREAM_COUNT);

	wbTime_start(GPU, "Allocating GPU memory.");
	for(int i=0; i<CUDA_STREAM_COUNT; i++)
	{
 		cudaMalloc((void**)&deviceInput1[i], segmentSize);
		cudaMalloc((void**)&deviceInput2[i], segmentSize);
		cudaMalloc((void**)&deviceOutput[i], segmentSize);
	}
    wbTime_stop(GPU, "Allocating GPU memory.");

	wbTime_start(Compute, "Performing CUDA operations");
	
	cudaStream_t stream[CUDA_STREAM_COUNT];
	for(int i=0; i<CUDA_STREAM_COUNT; i++)
	{
		cudaStreamCreate(&(stream[i]));
	}
	
	for(int i=0; i<n; i+=SEGMENT_SIZE*CUDA_STREAM_COUNT)
	{
		for(int j=0; j<CUDA_STREAM_COUNT; j++)
		{
			if(i+((j+1)*SEGMENT_SIZE)<=inputLength)
			{
				//wbLog(TRACE, "Copying to Device 1 size = ", SEGMENT_SIZE);
				cudaMemcpyAsync(deviceInput1[j], hostInput1+i+(j*SEGMENT_SIZE), SEGMENT_SIZE*sizeof(float), cudaMemcpyHostToDevice, stream[j]);
				cudaMemcpyAsync(deviceInput2[j], hostInput2+i+(j*SEGMENT_SIZE), SEGMENT_SIZE*sizeof(float), cudaMemcpyHostToDevice, stream[j]);
			}
			else
			{
				int start = i+(j*SEGMENT_SIZE);
				int diff = inputLength - start;
				if(diff > 0)
				{
					//wbLog(TRACE, "Copying to Device 2 size = ", diff);
					cudaMemcpyAsync(deviceInput1[j], hostInput1+i+(j*SEGMENT_SIZE), diff*sizeof(float), cudaMemcpyHostToDevice, stream[j]);
					cudaMemcpyAsync(deviceInput2[j], hostInput2+i+(j*SEGMENT_SIZE), diff*sizeof(float), cudaMemcpyHostToDevice, stream[j]);
				}
			}
		}
		
		for(int j=0; j<CUDA_STREAM_COUNT; j++)
		{
			vecAdd<<<SEGMENT_SIZE/BLOCK_SIZE, BLOCK_SIZE, 0, stream[j]>>>(deviceInput1[j], deviceInput2[j], deviceOutput[j], inputLength);
		}
		
		for(int j=0; j<CUDA_STREAM_COUNT; j++)
		{
			if(i+((j+1)*SEGMENT_SIZE)<=inputLength)
			{
				//wbLog(TRACE, "Copying to Host 1 size = ", SEGMENT_SIZE);
				cudaMemcpyAsync(hostOutput+i+(j*SEGMENT_SIZE), deviceOutput[j], SEGMENT_SIZE*sizeof(float), cudaMemcpyDeviceToHost, stream[j]);
			}
			else
			{
				int start = i+(j*SEGMENT_SIZE);
				int diff = inputLength - start;
				if(diff > 0)
				{
					//wbLog(TRACE, "Copying to Host 2 size = ", diff);
					cudaMemcpyAsync(hostOutput+i+(j*SEGMENT_SIZE), deviceOutput[j], diff*sizeof(float), cudaMemcpyDeviceToHost, stream[j]);
				}
			}
		}
	}
	
	for(int i=0; i<CUDA_STREAM_COUNT; i++)
	{
		cudaStreamDestroy(stream[i]);
	}
	
	wbTime_stop(Compute, "Performing CUDA operations");
	
	wbTime_start(GPU, "Freeing GPU Memory");
	for(int i=0; i<CUDA_STREAM_COUNT; i++)
	{
		cudaFree(deviceOutput[i]);
		cudaFree(deviceInput2[i]);
		cudaFree(deviceInput1[i]);
	}
    wbTime_stop(GPU, "Freeing GPU Memory");

    wbSolution(args, hostOutput, inputLength);

    free(hostInput1);
    free(hostInput2);
    free(hostOutput);

    return 0;
}

