#include    <wb.h>

#define wbCheck(stmt) do {                                 \
        cudaError_t err = stmt;                            \
        if (err != cudaSuccess) {                          \
            wbLog(ERROR, "Failed to run stmt ", #stmt);    \
            return -1;                                     \
        }                                                  \
    } while(0)

#define MASK_WIDTH				5
#define MASK_RADIUS				MASK_WIDTH/2
#define I_TILE_WIDTH			16
#define O_TILE_WIDTH			(I_TILE_WIDTH - 2*(MASK_WIDTH/2))
#define BLOCK_WIDTH				I_TILE_WIDTH

#define clamp(x, start, end) min(max(x, start), end)


/**
 * GPU version of the convolution image transformation
 */
__global__ void convolution2D(float * input, float * output,
							  int height, int width, int channels,
							  const float * __restrict__ M)
{
	// Shared memory input part
	__shared__ float I[I_TILE_WIDTH][I_TILE_WIDTH]; // 16 Width

	/*
	 * retrieve element position in output image from thread within grid:
	 * Regardless of each block element, the move is based on the output tile.
	 * Each block contains a thread that will help getting one output element
	 */
	int oRow  = blockIdx.y * O_TILE_WIDTH + threadIdx.y;
	int oCol  = blockIdx.x * O_TILE_WIDTH + threadIdx.x;
	int chan = blockIdx.z; // channel

	// final value for cumulation
	float accum = 0.0;

	// input element matrix coordinates - may be negative
	int row = oRow - MASK_RADIUS;
	int col = oCol - MASK_RADIUS;

	/*
	 * Load the tile that will be processed in this block:
	 * When out of the picture, load 0 as an element. 
	 * When inside the picture, load the element matching the height, width and channel
	 */
	if((col >= 0) && (col < width)
			&& (row >= 0) && (row < height))
	{
		unsigned int index = (row * width + col) * channels + chan;
		I[threadIdx.y][threadIdx.x] = input[index]; // 1 global memory read operation here
	}
	else
	{
		I[threadIdx.y][threadIdx.x] = 0.0f;
	}
	
	// post load sync - make sure everyone is ready
	__syncthreads();

	/* Exclude computation outside the output elements within the block:
	 * From one block to another, there is an overlap that will take care of the other 16 - 12 elements
	 */ 
	if(threadIdx.x < O_TILE_WIDTH && threadIdx.y < O_TILE_WIDTH) // from 0 to 11
	{
		// input indices + mask => compute element using shared memory
		for(unsigned int mCol = 0; mCol < MASK_WIDTH; ++mCol)
		{
			for(unsigned int mRow = 0; mRow < MASK_WIDTH; ++mRow)
			{
				// define mask matching shared tile coordinates
				unsigned int inCol = threadIdx.x + mCol;
				unsigned int inRow = threadIdx.y + mRow;

				// fetch matching values from both mask matrix and sub tile matrix
				float imagePixel = I[inRow][inCol];
				float maskValue = M[mRow * MASK_WIDTH + mCol];

				accum += (imagePixel * maskValue); // 2 floating operations here
			}
		}
		// oRow and oCol start at 0, check upper boundaries (may be false at end of grid)
		if(oRow < height && oCol < width)
		{
			unsigned int oIndex = (oRow * width + oCol) * channels + chan;
			output[oIndex] = clamp(accum, 0.0, 1.0); // use the Macro defined function here (replacement)
		}
	}
	__syncthreads(); // post processing sync
}

/*
 * Main program
 */
int main(int argc, char* argv[]) {
    wbArg_t arg;
    int maskRows;
    int maskColumns;

	int imageChannels;
    int imageWidth;
    int imageHeight;
    // int imagePitch; // pitch is intended to be used to work only per DRAM burst

	char * inputImageFile;
    char * inputMaskFile;

	wbImage_t inputImage;
    wbImage_t outputImage;

	// Host data
	float * hostInputImageData;
    float * hostOutputImageData;
    float * hostMaskData;

	// Device data
	float * deviceInputImageData;
    float * deviceOutputImageData;
    float * deviceMaskData;

    wbLog(INFO, "Start Convolution process");
    arg = wbArg_read(argc, argv); /* parse the input arguments */

    wbLog(INFO, "Load files and data...");
    inputImageFile = wbArg_getInputFile(arg, 0);
    inputMaskFile = wbArg_getInputFile(arg, 1);

    inputImage = wbImport(inputImageFile);
    hostMaskData = (float *) wbImport(inputMaskFile, &maskRows, &maskColumns);

    assert(maskRows == 5); /* mask height is fixed to 5 in this mp */
    assert(maskColumns == 5); /* mask width is fixed to 5 in this mp */

	// get image data for dimension setup and boundaries
    imageWidth = wbImage_getWidth(inputImage);
    imageHeight = wbImage_getHeight(inputImage);
    imageChannels = wbImage_getChannels(inputImage);

	// imagePitch = wbImage_getPitch(inputImage); // load of the pitch (memory management)

    wbLog(INFO, "Create output...");
	// create output structure and data
    outputImage = wbImage_new(imageWidth, imageHeight, imageChannels);

    hostInputImageData = wbImage_getData(inputImage);
    hostOutputImageData = wbImage_getData(outputImage);

    wbLog(INFO, "Start computation...");
    wbTime_start(GPU, "Doing GPU Computation (memory + compute)");

	wbLog(INFO, "Allocate memory...");
    wbTime_start(GPU, "Doing GPU memory allocation");
    cudaMalloc((void **) &deviceInputImageData, imageWidth * imageHeight * imageChannels * sizeof(float));
    cudaMalloc((void **) &deviceOutputImageData, imageWidth * imageHeight * imageChannels * sizeof(float));
    cudaMalloc((void **) &deviceMaskData, maskRows * maskColumns * sizeof(float));
	wbTime_stop(GPU, "Doing GPU memory allocation");

	wbLog(INFO, "Copy data to device...");
	wbTime_start(Copy, "Copying data to the GPU");

	/*
	 * Memory copy to device and mask to constant memory
	 */
    cudaMemcpy(deviceInputImageData,
               hostInputImageData,
               imageWidth * imageHeight * imageChannels * sizeof(float),
               cudaMemcpyHostToDevice);
    cudaMemcpy(deviceMaskData,
               hostMaskData,
               maskRows * maskColumns * sizeof(float),
               cudaMemcpyHostToDevice);

    wbTime_stop(Copy, "Copying data to the GPU");

    wbTime_start(Compute, "Doing the computation on the GPU");

	wbLog(INFO, "Define structure dimension...");
	/*
	 * The structure is based on two concept: memory tile for input and output.
	 * Since the mask has a width = MASK_WIDTH, then each element require an extra radius = MASK_WIDTH /2.
	 * Therefore, for the first element or the last element (among others) the kernel computes:
	 * - it needs two elements before (might be set to 0),
	 * - and 2 elements after (might be 0)...
	 * Hence, the block size is matching the input size (and tile), and the number of block required is
	 * "as many as the output size requires to cover"
	 *
	 * note: in the Macro, BLOCK_WIDTH = I_TILE_WIDTH
	 */
	unsigned int bdimx, bdimy, gdimx, gdimy, gdimz;
	bdimx = BLOCK_WIDTH;
	bdimy = BLOCK_WIDTH;

	// set grid size depending on image and output tile (the elements to compute)
	gdimx = 1 + ((imageWidth - 1) / O_TILE_WIDTH);
	gdimy = 1 + ((imageHeight - 1) / O_TILE_WIDTH);
	gdimz = imageChannels;

	wbLog(INFO, "Setting structure using dimensions ...");

	// define CUDA structure
	dim3 dimBlock(bdimx, bdimy);
	dim3 dimGrid(gdimx, gdimy, gdimz);

	wbLog(TRACE, "Using block computation structure: ", bdimx, " x ", bdimy, " x ", 1);
	wbLog(TRACE, "Using grid computation structure: ", gdimx, " x ", gdimy, " x ", gdimz);
	convolution2D<<<dimGrid, dimBlock>>>(deviceInputImageData, deviceOutputImageData, imageHeight, imageWidth, imageChannels, deviceMaskData);

	wbTime_stop(Compute, "Doing the computation on the GPU");

	wbLog(INFO, "Copy data back to host ...");
    wbTime_start(Copy, "Copying data from the GPU");
    cudaMemcpy(hostOutputImageData,
               deviceOutputImageData,
               imageWidth * imageHeight * imageChannels * sizeof(float),
               cudaMemcpyDeviceToHost);
	wbTime_stop(Copy, "Copying data from the GPU");

    wbTime_stop(GPU, "Doing GPU Computation (memory + compute)");

	wbLog(INFO, "Process solution check ...");
    wbSolution(arg, outputImage);

	// Free memory of the device
    cudaFree(deviceInputImageData);
    cudaFree(deviceOutputImageData);
    cudaFree(deviceMaskData);

	// Free memory of the host
    free(hostMaskData);
    wbImage_delete(outputImage);
    wbImage_delete(inputImage);

    return 0;
}
